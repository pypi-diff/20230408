# Comparing `tmp/mltable-1.2.0-py3-none-any.whl.zip` & `tmp/mltable-1.3.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,72 +1,72 @@
-Zip file size: 177441 bytes, number of entries: 70
--rw-rw-rw-  2.0 fat      937 b- defN 23-Feb-23 01:10 mltable/__init__.py
--rw-rw-rw-  2.0 fat     3078 b- defN 23-Feb-23 01:10 mltable/_utils.py
--rw-rw-rw-  2.0 fat     3773 b- defN 23-Feb-23 01:10 mltable/_validation_and_error_handler.py
--rw-rw-rw-  2.0 fat    89910 b- defN 23-Feb-23 01:10 mltable/mltable.py
--rw-rw-rw-  2.0 fat      183 b- defN 23-Feb-23 01:11 mltable/_aml_utilities/__init__.py
--rw-rw-rw-  2.0 fat     6778 b- defN 23-Feb-23 01:11 mltable/_aml_utilities/_aml_rest_client_helper.py
--rw-rw-rw-  2.0 fat    23222 b- defN 23-Feb-23 01:11 mltable/_aml_utilities/_azureml_token_authentication.py
--rw-rw-rw-  2.0 fat      893 b- defN 23-Feb-23 01:14 mltable/_aml_utilities/_restclient/__init__.py
--rw-rw-rw-  2.0 fat     4218 b- defN 23-Feb-23 01:14 mltable/_aml_utilities/_restclient/_azure_machine_learning_workspaces.py
--rw-rw-rw-  2.0 fat     3538 b- defN 23-Feb-23 01:14 mltable/_aml_utilities/_restclient/_configuration.py
--rw-rw-rw-  2.0 fat     1561 b- defN 23-Feb-23 01:14 mltable/_aml_utilities/_restclient/_patch.py
--rw-rw-rw-  2.0 fat      495 b- defN 23-Feb-23 01:14 mltable/_aml_utilities/_restclient/_version.py
--rw-rw-rw-  2.0 fat      365 b- defN 23-Feb-23 01:14 mltable/_aml_utilities/_restclient/models.py
--rw-rw-rw-  2.0 fat      893 b- defN 23-Feb-23 01:17 mltable/_aml_utilities/_restclient/dataset/__init__.py
--rw-rw-rw-  2.0 fat     3954 b- defN 23-Feb-23 01:17 mltable/_aml_utilities/_restclient/dataset/_azure_machine_learning_workspaces.py
--rw-rw-rw-  2.0 fat     3209 b- defN 23-Feb-23 01:17 mltable/_aml_utilities/_restclient/dataset/_configuration.py
--rw-rw-rw-  2.0 fat     1561 b- defN 23-Feb-23 01:17 mltable/_aml_utilities/_restclient/dataset/_patch.py
--rw-rw-rw-  2.0 fat     1255 b- defN 23-Feb-23 01:17 mltable/_aml_utilities/_restclient/dataset/_vendor.py
--rw-rw-rw-  2.0 fat      495 b- defN 23-Feb-23 01:17 mltable/_aml_utilities/_restclient/dataset/_version.py
--rw-rw-rw-  2.0 fat    10737 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/dataset/models/__init__.py
--rw-rw-rw-  2.0 fat     4514 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/dataset/models/_azure_machine_learning_workspaces_enums.py
--rw-rw-rw-  2.0 fat   116583 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/dataset/models/_models.py
--rw-rw-rw-  2.0 fat   125881 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/dataset/models/_models_py3.py
--rw-rw-rw-  2.0 fat      585 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/dataset/operations/__init__.py
--rw-rw-rw-  2.0 fat    67091 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/dataset/operations/_data_version_operations.py
--rw-rw-rw-  2.0 fat      893 b- defN 23-Feb-23 01:17 mltable/_aml_utilities/_restclient/token/__init__.py
--rw-rw-rw-  2.0 fat     3697 b- defN 23-Feb-23 01:17 mltable/_aml_utilities/_restclient/token/_azure_machine_learning_workspaces.py
--rw-rw-rw-  2.0 fat     3068 b- defN 23-Feb-23 01:17 mltable/_aml_utilities/_restclient/token/_configuration.py
--rw-rw-rw-  2.0 fat     1559 b- defN 23-Feb-23 01:17 mltable/_aml_utilities/_restclient/token/_patch.py
--rw-rw-rw-  2.0 fat     1224 b- defN 23-Feb-23 01:17 mltable/_aml_utilities/_restclient/token/_vendor.py
--rw-rw-rw-  2.0 fat      495 b- defN 23-Feb-23 01:17 mltable/_aml_utilities/_restclient/token/_version.py
--rw-rw-rw-  2.0 fat      837 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/token/aio/__init__.py
--rw-rw-rw-  2.0 fat     3645 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/token/aio/_azure_machine_learning_workspaces.py
--rw-rw-rw-  2.0 fat     3021 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/token/aio/_configuration.py
--rw-rw-rw-  2.0 fat     1559 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/token/aio/_patch.py
--rw-rw-rw-  2.0 fat      563 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/token/aio/operations/__init__.py
--rw-rw-rw-  2.0 fat     7639 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/token/aio/operations/_runs_operations.py
--rw-rw-rw-  2.0 fat    10472 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/token/models/__init__.py
--rw-rw-rw-  2.0 fat     2244 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/token/models/_azure_machine_learning_workspaces_enums.py
--rw-rw-rw-  2.0 fat   166455 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/token/models/_models.py
--rw-rw-rw-  2.0 fat   179783 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/token/models/_models_py3.py
--rw-rw-rw-  2.0 fat      563 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/token/operations/__init__.py
--rw-rw-rw-  2.0 fat    10661 b- defN 23-Feb-23 01:19 mltable/_aml_utilities/_restclient/token/operations/_runs_operations.py
--rw-rw-rw-  2.0 fat      183 b- defN 23-Feb-23 01:11 mltable/_common/__init__.py
--rw-rw-rw-  2.0 fat     2393 b- defN 23-Feb-23 01:11 mltable/_common/chained_identity.py
--rw-rw-rw-  2.0 fat      933 b- defN 23-Feb-23 01:11 mltable/_common/logged_lock.py
--rw-rw-rw-  2.0 fat      183 b- defN 23-Feb-23 01:14 mltable/_common/async_utils/__init__.py
--rw-rw-rw-  2.0 fat     2827 b- defN 23-Feb-23 01:14 mltable/_common/async_utils/async_task.py
--rw-rw-rw-  2.0 fat     2329 b- defN 23-Feb-23 01:14 mltable/_common/async_utils/daemon.py
--rw-rw-rw-  2.0 fat     5911 b- defN 23-Feb-23 01:14 mltable/_common/async_utils/task_queue.py
--rw-rw-rw-  2.0 fat     1112 b- defN 23-Feb-23 01:14 mltable/_common/async_utils/worker_pool.py
--rw-rw-rw-  2.0 fat    31813 b- defN 23-Feb-23 01:11 mltable/schema/MLTable.json
--rw-rw-rw-  2.0 fat        0 b- defN 23-Feb-23 01:11 mltable/tests/__init__.py
--rw-rw-rw-  2.0 fat     2129 b- defN 23-Feb-23 01:11 mltable/tests/conftest.py
--rw-rw-rw-  2.0 fat     1454 b- defN 23-Feb-23 01:11 mltable/tests/helper_functions.py
--rw-rw-rw-  2.0 fat     9825 b- defN 23-Feb-23 01:11 mltable/tests/test_from_delta_lake.py
--rw-rw-rw-  2.0 fat     3968 b- defN 23-Feb-23 01:11 mltable/tests/test_from_json_lines.py
--rw-rw-rw-  2.0 fat    61415 b- defN 23-Feb-23 01:11 mltable/tests/test_mltable_authoring_apis.py
--rw-rw-rw-  2.0 fat    15302 b- defN 23-Feb-23 01:11 mltable/tests/test_mltable_inner_functions.py
--rw-rw-rw-  2.0 fat     4779 b- defN 23-Feb-23 01:11 mltable/tests/test_mltable_load.py
--rw-rw-rw-  2.0 fat     9658 b- defN 23-Feb-23 01:11 mltable/tests/test_mltable_load_to_pandas.py
--rw-rw-rw-  2.0 fat     6708 b- defN 23-Feb-23 01:11 mltable/tests/test_mltable_save.py
--rw-rw-rw-  2.0 fat     1477 b- defN 23-Feb-23 01:11 mltable/tests/test_partition_api.py
--rw-rw-rw-  2.0 fat     4438 b- defN 23-Feb-23 01:11 mltable/tests/test_schema.py
--rw-rw-rw-  2.0 fat     5349 b- defN 23-Feb-23 01:11 mltable/tests/test_validation_and_error_handler.py
--rw-rw-rw-  2.0 fat     1021 b- defN 23-Feb-23 01:21 mltable-1.2.0.dist-info/LICENSE.txt
--rw-rw-rw-  2.0 fat     3782 b- defN 23-Feb-23 01:21 mltable-1.2.0.dist-info/METADATA
--rw-rw-rw-  2.0 fat       97 b- defN 23-Feb-23 01:21 mltable-1.2.0.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        8 b- defN 23-Feb-23 01:21 mltable-1.2.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     7336 b- defN 23-Feb-23 01:21 mltable-1.2.0.dist-info/RECORD
-70 files, 1060517 bytes uncompressed, 165285 bytes compressed:  84.4%
+Zip file size: 178694 bytes, number of entries: 70
+-rw-rw-rw-  2.0 fat      937 b- defN 23-Apr-07 22:56 mltable/__init__.py
+-rw-rw-rw-  2.0 fat     4193 b- defN 23-Apr-07 22:56 mltable/_utils.py
+-rw-rw-rw-  2.0 fat     4404 b- defN 23-Apr-07 22:56 mltable/_validation_and_error_handler.py
+-rw-rw-rw-  2.0 fat    90746 b- defN 23-Apr-07 22:56 mltable/mltable.py
+-rw-rw-rw-  2.0 fat      183 b- defN 23-Apr-07 22:57 mltable/_aml_utilities/__init__.py
+-rw-rw-rw-  2.0 fat     7321 b- defN 23-Apr-07 22:57 mltable/_aml_utilities/_aml_rest_client_helper.py
+-rw-rw-rw-  2.0 fat    23222 b- defN 23-Apr-07 22:57 mltable/_aml_utilities/_azureml_token_authentication.py
+-rw-rw-rw-  2.0 fat      893 b- defN 23-Apr-07 22:59 mltable/_aml_utilities/_restclient/__init__.py
+-rw-rw-rw-  2.0 fat     4218 b- defN 23-Apr-07 22:59 mltable/_aml_utilities/_restclient/_azure_machine_learning_workspaces.py
+-rw-rw-rw-  2.0 fat     3538 b- defN 23-Apr-07 22:59 mltable/_aml_utilities/_restclient/_configuration.py
+-rw-rw-rw-  2.0 fat     1561 b- defN 23-Apr-07 22:59 mltable/_aml_utilities/_restclient/_patch.py
+-rw-rw-rw-  2.0 fat      495 b- defN 23-Apr-07 22:59 mltable/_aml_utilities/_restclient/_version.py
+-rw-rw-rw-  2.0 fat      365 b- defN 23-Apr-07 22:59 mltable/_aml_utilities/_restclient/models.py
+-rw-rw-rw-  2.0 fat      893 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/dataset/__init__.py
+-rw-rw-rw-  2.0 fat     3954 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/dataset/_azure_machine_learning_workspaces.py
+-rw-rw-rw-  2.0 fat     3209 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/dataset/_configuration.py
+-rw-rw-rw-  2.0 fat     1561 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/dataset/_patch.py
+-rw-rw-rw-  2.0 fat     1255 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/dataset/_vendor.py
+-rw-rw-rw-  2.0 fat      495 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/dataset/_version.py
+-rw-rw-rw-  2.0 fat    10737 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/dataset/models/__init__.py
+-rw-rw-rw-  2.0 fat     4514 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/dataset/models/_azure_machine_learning_workspaces_enums.py
+-rw-rw-rw-  2.0 fat   116583 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/dataset/models/_models.py
+-rw-rw-rw-  2.0 fat   125881 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/dataset/models/_models_py3.py
+-rw-rw-rw-  2.0 fat      585 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/dataset/operations/__init__.py
+-rw-rw-rw-  2.0 fat    67091 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/dataset/operations/_data_version_operations.py
+-rw-rw-rw-  2.0 fat      893 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/token/__init__.py
+-rw-rw-rw-  2.0 fat     3697 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/token/_azure_machine_learning_workspaces.py
+-rw-rw-rw-  2.0 fat     3068 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/token/_configuration.py
+-rw-rw-rw-  2.0 fat     1559 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/token/_patch.py
+-rw-rw-rw-  2.0 fat     1224 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/token/_vendor.py
+-rw-rw-rw-  2.0 fat      495 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/token/_version.py
+-rw-rw-rw-  2.0 fat      837 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/token/aio/__init__.py
+-rw-rw-rw-  2.0 fat     3645 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/token/aio/_azure_machine_learning_workspaces.py
+-rw-rw-rw-  2.0 fat     3021 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/token/aio/_configuration.py
+-rw-rw-rw-  2.0 fat     1559 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/token/aio/_patch.py
+-rw-rw-rw-  2.0 fat      563 b- defN 23-Apr-07 23:01 mltable/_aml_utilities/_restclient/token/aio/operations/__init__.py
+-rw-rw-rw-  2.0 fat     7639 b- defN 23-Apr-07 23:01 mltable/_aml_utilities/_restclient/token/aio/operations/_runs_operations.py
+-rw-rw-rw-  2.0 fat    10472 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/token/models/__init__.py
+-rw-rw-rw-  2.0 fat     2244 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/token/models/_azure_machine_learning_workspaces_enums.py
+-rw-rw-rw-  2.0 fat   166455 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/token/models/_models.py
+-rw-rw-rw-  2.0 fat   179783 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/token/models/_models_py3.py
+-rw-rw-rw-  2.0 fat      563 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/token/operations/__init__.py
+-rw-rw-rw-  2.0 fat    10661 b- defN 23-Apr-07 23:00 mltable/_aml_utilities/_restclient/token/operations/_runs_operations.py
+-rw-rw-rw-  2.0 fat      183 b- defN 23-Apr-07 22:57 mltable/_common/__init__.py
+-rw-rw-rw-  2.0 fat     2393 b- defN 23-Apr-07 22:57 mltable/_common/chained_identity.py
+-rw-rw-rw-  2.0 fat      933 b- defN 23-Apr-07 22:57 mltable/_common/logged_lock.py
+-rw-rw-rw-  2.0 fat      183 b- defN 23-Apr-07 22:59 mltable/_common/async_utils/__init__.py
+-rw-rw-rw-  2.0 fat     2827 b- defN 23-Apr-07 22:59 mltable/_common/async_utils/async_task.py
+-rw-rw-rw-  2.0 fat     2329 b- defN 23-Apr-07 22:59 mltable/_common/async_utils/daemon.py
+-rw-rw-rw-  2.0 fat     5911 b- defN 23-Apr-07 22:59 mltable/_common/async_utils/task_queue.py
+-rw-rw-rw-  2.0 fat     1112 b- defN 23-Apr-07 22:59 mltable/_common/async_utils/worker_pool.py
+-rw-rw-rw-  2.0 fat    31845 b- defN 23-Apr-07 22:57 mltable/schema/MLTable.json
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-07 22:57 mltable/tests/__init__.py
+-rw-rw-rw-  2.0 fat     2129 b- defN 23-Apr-07 22:57 mltable/tests/conftest.py
+-rw-rw-rw-  2.0 fat     2120 b- defN 23-Apr-07 22:57 mltable/tests/helper_functions.py
+-rw-rw-rw-  2.0 fat    11329 b- defN 23-Apr-07 22:57 mltable/tests/test_from_delta_lake.py
+-rw-rw-rw-  2.0 fat     3968 b- defN 23-Apr-07 22:57 mltable/tests/test_from_json_lines.py
+-rw-rw-rw-  2.0 fat    61415 b- defN 23-Apr-07 22:57 mltable/tests/test_mltable_authoring_apis.py
+-rw-rw-rw-  2.0 fat    15184 b- defN 23-Apr-07 22:57 mltable/tests/test_mltable_inner_functions.py
+-rw-rw-rw-  2.0 fat     5148 b- defN 23-Apr-07 22:57 mltable/tests/test_mltable_load.py
+-rw-rw-rw-  2.0 fat     9662 b- defN 23-Apr-07 22:57 mltable/tests/test_mltable_load_to_pandas.py
+-rw-rw-rw-  2.0 fat     6708 b- defN 23-Apr-07 22:57 mltable/tests/test_mltable_save.py
+-rw-rw-rw-  2.0 fat     1477 b- defN 23-Apr-07 22:57 mltable/tests/test_partition_api.py
+-rw-rw-rw-  2.0 fat     4438 b- defN 23-Apr-07 22:57 mltable/tests/test_schema.py
+-rw-rw-rw-  2.0 fat     5294 b- defN 23-Apr-07 22:57 mltable/tests/test_validation_and_error_handler.py
+-rw-rw-rw-  2.0 fat     1021 b- defN 23-Apr-07 23:07 mltable-1.3.0.dist-info/LICENSE.txt
+-rw-rw-rw-  2.0 fat     3886 b- defN 23-Apr-07 23:07 mltable-1.3.0.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       97 b- defN 23-Apr-07 23:07 mltable-1.3.0.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        8 b- defN 23-Apr-07 23:07 mltable-1.3.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     7337 b- defN 23-Apr-07 23:07 mltable-1.3.0.dist-info/RECORD
+70 files, 1066149 bytes uncompressed, 166538 bytes compressed:  84.4%
```

## zipnote {}

```diff
@@ -189,23 +189,23 @@
 
 Filename: mltable/tests/test_schema.py
 Comment: 
 
 Filename: mltable/tests/test_validation_and_error_handler.py
 Comment: 
 
-Filename: mltable-1.2.0.dist-info/LICENSE.txt
+Filename: mltable-1.3.0.dist-info/LICENSE.txt
 Comment: 
 
-Filename: mltable-1.2.0.dist-info/METADATA
+Filename: mltable-1.3.0.dist-info/METADATA
 Comment: 
 
-Filename: mltable-1.2.0.dist-info/WHEEL
+Filename: mltable-1.3.0.dist-info/WHEEL
 Comment: 
 
-Filename: mltable-1.2.0.dist-info/top_level.txt
+Filename: mltable-1.3.0.dist-info/top_level.txt
 Comment: 
 
-Filename: mltable-1.2.0.dist-info/RECORD
+Filename: mltable-1.3.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## mltable/_utils.py

```diff
@@ -1,51 +1,57 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 import json
 from jsonschema import validate
 import os
 import re
+import yaml
 
 from azureml.dataprep.api.mltable._mltable_helper import _parse_path_format, _PathType
 from azureml.dataprep.api._loggerfactory import _LoggerFactory
 
 
 _logger = _LoggerFactory.get_logger('MLTableUtils')
 _long_form_aml_uri = re.compile(
     r'^azureml://subscriptions/([^\/]+)/resourcegroups/([^\/]+)/'
     r'(?:providers/Microsoft.MachineLearningServices/)?workspaces/([^\/]+)/(.*)',
     re.IGNORECASE)
 
 
-def _is_local_path(path):
-    return _parse_path_format(path)[0] == _PathType.local
-
+_PATHS_KEY = 'paths'
 
-def _make_all_paths_absolute(mltable_yaml_dict, base_path, is_local=False):
-    if base_path and 'paths' in mltable_yaml_dict:
-        for path_dict in mltable_yaml_dict['paths']:
-            for path_prop, path in path_dict.items():
-                # get absolute path from base_path + relative path
-                if _is_local_path(path) and not path.startswith('file://'):
-                    # assume that local relative paths are co-located in directory of MLTable file
-                    path = os.path.normpath(path)
-
-                    if not os.path.isabs(path):
-                        # when path == '.' it represents the current dir, which is base_path ex) folder: .
-                        path = base_path if _path_is_current_directory_variant(path) else os.path.join(base_path, path)
 
-                    if _is_local_path(base_path):
-                        path = os.path.normpath(path)
+def _is_local_path(path):
+    return _parse_path_format(path)[0] == _PathType.local
 
-                    if is_local:
-                        path = "file://" + os.path.abspath(path)
 
-                    path_dict[path_prop] = path
+def _make_all_paths_absolute(mltable_yaml_dict, base_path):
+    def format_path_pair(path_prop, path, is_base_path_local):
+        # get absolute path from base_path + relative path
+        if _is_local_path(path) and not path.startswith('file://'):
+            # assumes that local relative paths are co-located in directory of MLTable file
+            path = os.path.normpath(path)
+
+            if not os.path.isabs(path):
+                # when path == '.' it represents the current dir, which is base_path ex) folder: .
+                path = base_path if _path_is_current_directory_variant(path) else os.path.join(base_path, path)
+
+            if is_base_path_local:
+                path = os.path.normpath(path)
+                path = "file://" + os.path.abspath(path)
+
+        return path_prop, path
+
+    def format_paths(paths, is_base_path_local):
+        return list(map(
+            lambda path_dict: dict(map(lambda x: format_path_pair(*x, is_base_path_local), path_dict.items())), paths))
 
+    if base_path and _PATHS_KEY in mltable_yaml_dict:
+        mltable_yaml_dict[_PATHS_KEY] = format_paths(mltable_yaml_dict[_PATHS_KEY], _is_local_path(base_path))
     return mltable_yaml_dict
 
 
 def _path_is_current_directory_variant(path):
     return path in ['.', './', '.\\']
 
 
@@ -56,23 +62,43 @@
         try:
             schema = json.load(stream)
         except json.decoder.JSONDecodeError:
             raise RuntimeError("MLTable json schema is not a valid json file.")
     try:
         validate(mltable_yaml_dict, schema)
     except Exception as e:
-        _logger.warning("MLTable validation failed with error: {}".format(e.args))
-        raise ValueError("Given MLTable does not adhere to the AzureML MLTable schema: {}".format(e.args))
+        _logger.warning(f"MLTable validation failed with error: {e.args[0]}")
+        raise ValueError(f"Given MLTable does not adhere to the AzureML MLTable schema: {e.args[0]}")
 
 
 # will switch to the api from dataprep package once new dataprep version is released
 def _parse_workspace_context_from_longform_uri(uri):
     long_form_uri_match = _long_form_aml_uri.match(uri)
 
     if long_form_uri_match:
         return {
             'subscription': long_form_uri_match.group(1),
             'resource_group': long_form_uri_match.group(2),
             'workspace_name': long_form_uri_match.group(3)
         }
 
     return None
+
+
+# utility function to remove all the empty and null fields from a nested dict
+def _remove_empty_and_null_fields(mltable_yaml_dict):
+    if isinstance(mltable_yaml_dict, dict):
+        return {k : v for k, v in
+                ((k, _remove_empty_and_null_fields(v)) for k, v in mltable_yaml_dict.items()) if v is not None}
+    if isinstance(mltable_yaml_dict, list):
+        return [v for v in map(_remove_empty_and_null_fields, mltable_yaml_dict) if v is not None]
+    return mltable_yaml_dict
+
+
+class MLTableYamlCleaner(yaml.YAMLObject):
+    # _dataflow.to_yaml_string() serializes Serde units (anonymous value containing no data) as nulls.
+    # this results in nested fields with empty values being serialized with nulls as values.
+    def __init__(self, mltable_yaml_dict):
+        self.cleaned_mltable_yaml_dict = _remove_empty_and_null_fields(mltable_yaml_dict)
+
+    def __repr__(self):
+        return yaml.dump(self.cleaned_mltable_yaml_dict)
```

## mltable/_validation_and_error_handler.py

```diff
@@ -8,27 +8,26 @@
         return []
     from azureml.dataprep.native import DataPrepError, StreamInfo
     # Check the download error for each record if its user error
     actual_download_list = []
     error_list = []
     for record in download_records:
         value = record['DestinationFile']
-        print(f'value {value}')
         if isinstance(value, StreamInfo):
             actual_download_list.append(value.resource_identifier)
         elif isinstance(value, DataPrepError):
             resource_identifier = value.originalValue
             if ignore_not_found and value.errorCode == "Microsoft.DPrep.ErrorValues.SourceFileNotFound":
-                logger.warn("'{}' hasn't been downloaded as it was not present at the source. \
-                    Download is proceeding.".format(resource_identifier))
+                logger.warning(f"'{resource_identifier}' hasn't been downloaded as it was not present at the source. \
+                               Download is proceeding.")
             else:
                 error_list.append((resource_identifier, value.errorCode))
         else:
             raise RuntimeError(f'Unexpected error during file download.{value}')
-    print(f'error_lis {error_list}')
+
     if error_list:
         # this will throw ValueError for user error
         # or RuntimeError for system error based on set of errors encountered
         _download_error_handler(error_list)
     return actual_download_list
 
 
@@ -58,18 +57,28 @@
         if not is_user_error(error):
             all_user_errors = False
             system_error_msg += error
             break
     raise ValueError(message) if all_user_errors else RuntimeError(system_error_msg)
 
 
-# temp user error classification for rslex errors
-def _classify_known_user_error_from_rslex(exception_message):
+# temp user error classification
+def _classify_known_user_error(exception_message, ex=None):
     value_errors = ["InvalidUriScheme", "StreamError(NotFound)", "DataAccessError(NotFound)",
-                    "No such host is known", "No identity was found on compute", "Make sure uri is correct"]
-    if any(val_error in exception_message for val_error in value_errors):
-        raise ValueError(exception_message)
-    elif "ExecutionError(StreamError(PermissionDenied" in exception_message:
+                    "No such host is known", "No identity was found on compute", "Make sure uri is correct",
+                    "Authentication failed when trying to access the stream",
+                    "Invalid JSON in log record",
+                    "Invalid table version",
+                    "Only one of version or timestamp can be specified but not both.",
+                    "Unable to find any delta table metadata",
+                    "The requested stream was not found"]
+    if 'Python expression parse error' in exception_message:
+        raise ValueError(f'Not a valid python expression in filter. {exception_message}') from ex
+    elif 'ExecutionError(StreamError(PermissionDenied' in exception_message:
         raise ValueError(f'Getting permission error'
                          f'please make sure proper access is configured on storage: {exception_message}')
+    elif getattr(ex, 'error_code', None) in ('ScriptExecution.Validation', 'ScriptExecution.StreamAccess.NotFound'):
+        raise ValueError(exception_message)
+    elif any(val_error in exception_message for val_error in value_errors):
+        raise ValueError(exception_message)
     else:
         raise SystemError(exception_message)
```

## mltable/mltable.py

```diff
@@ -2,15 +2,14 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """
 Contains functionality to create and interact with MLTable objects
 """
 import atexit
 import os
-import copy
 import re
 import yaml
 from enum import Enum, auto
 import random
 import tempfile
 import urllib.parse
 import hashlib
@@ -24,16 +23,17 @@
 from azureml.dataprep.api.mltable._mltable_helper import _read_yaml, _download_mltable_yaml, \
     _parse_path_format, _PathType, _is_tabular
 from azureml.dataprep.rslex import PyRsDataflow
 from ._aml_utilities._aml_rest_client_helper import _get_data_asset_by_id, _get_data_asset_by_asset_uri, \
     _try_resolve_workspace_info, _has_sufficient_workspace_info, STORAGE_OPTION_KEY_AZUREML_SUBSCRIPTION, \
     STORAGE_OPTION_KEY_AZUREML_RESOURCEGROUP, STORAGE_OPTION_KEY_AZUREML_WORKSPACE
 
-from ._utils import _validate, _make_all_paths_absolute, _parse_workspace_context_from_longform_uri, _is_local_path
-from ._validation_and_error_handler import _get_and_validate_download_list, _classify_known_user_error_from_rslex
+from ._utils import _validate, _make_all_paths_absolute, _parse_workspace_context_from_longform_uri, _is_local_path, \
+    _PATHS_KEY, MLTableYamlCleaner
+from ._validation_and_error_handler import _get_and_validate_download_list, _classify_known_user_error
 from azureml.dataprep.api.typeconversions import FieldType
 from azureml.dataprep.api._rslex_executor import ensure_rslex_environment
 
 _APP_NAME = 'MLTable'
 _PUBLIC_API = 'PublicApi'
 _INTERNAL_API = 'InternalCall'
 _TRAITS_SECTION_KEY = 'traits'
@@ -42,15 +42,14 @@
 _TRAITS_SCHEMA_NAME = 'traits'
 _METADATA_SCHEMA_NAME = 'metadata'
 _logger = None
 
 # keys for MLTable sections
 _EXTRACT_PARTITION_FORMAT_KEY = 'extract_columns_from_partition_format'
 _PARTITION_FORMAT_KEY = 'partition_format'
-_PATHS_KEY = 'paths'
 _METADATA_KEY = 'metadata'
 _TRANSFORMATIONS_KEY = 'transformations'
 _READ_DELIMITED_KEY = 'read_delimited'
 _READ_JSON_KEY = 'read_json_lines'
 
 _CONVERT_COLUMNS_TYPES_TYPE_ERROR = ValueError('`convert_column_types` must be a dictionary where '
                                                'key is Union[str, Tuple[str]] and '
@@ -197,15 +196,16 @@
         """Configure conversion to 64-bit float."""
         return DataType._create(FieldType.DECIMAL)
 
     @staticmethod
     def to_bool(true_values: Optional[List[str]] = None,
                 false_values: Optional[List[str]] = None,
                 mismatch_as: Optional[str] = None):
-        """Configure conversion to bool. `true_values` & `false_values` must both be None or non-empty lists of,
+        """
+        Configure conversion to bool. `true_values` & `false_values` must both be None or non-empty lists of,
         string else an error will be thrown.
 
         :param true_values: List of values in dataset to designate as True.
             For example, ['1', 'yes'] will be replaced as [True, True].
             The true_values need to be present in the dataset otherwise None will be returned for values not present.
         :type true_values: builtin.list[str]
 
@@ -252,15 +252,16 @@
     @staticmethod
     def to_stream():
         """Configure conversion to stream."""
         return DataType._create(FieldType.STREAM)
 
     @staticmethod
     def to_datetime(formats: Union[str, List[str]], date_constant: Optional[str] = None):
-        """Configure conversion to datetime.
+        """
+        Configure conversion to datetime.
 
         :param formats: Formats to try for datetime conversion. For example `%d-%m-%Y` for data in "day-month-year",
             and `%Y-%m-%dT%H:%M:%S.%f` for "combined date and time representation" according to ISO 8601.
 
             * %Y: Year with 4 digits
 
             * %y: Year with 2 digits
@@ -439,18 +440,16 @@
     workspace_context = _parse_workspace_context_from_longform_uri(uri)
     if workspace_context:
         custom_dimensions.update(workspace_context)
     with _LoggerFactory.track_activity(_get_logger(), 'load', _PUBLIC_API,
                                        custom_dimensions) as activityLogger:
         try:
             path_type, base_path, match = _parse_path_format(uri)
-            is_local = False
             if path_type == _PathType.local:
                 base_path = os.path.abspath(base_path)
-                is_local = True
                 mltable_dict = _read_yaml(base_path)
                 if enable_validate:
                     _validate(mltable_dict)
             elif path_type == _PathType.cloud:
                 local_path = _download_mltable_yaml(uri)
                 mltable_dict = _read_yaml(local_path)
                 if enable_validate:
@@ -467,16 +466,16 @@
                     match, storage_options, enable_validate)
                 # path has been mapped to absolute path in _load_mltable_from_data_asset_uri
                 base_path = None
             else:
                 raise ValueError('The uri should be a valid path to a local or cloud directory which contains an '
                                  'MLTable file.')
             # v1 sql dataset doesnt have paths
-            orig_paths = copy.deepcopy(mltable_dict.get(_PATHS_KEY))  # make a copy to keep relative local file paths
-            mltable_dict = _make_all_paths_absolute(mltable_dict, base_path, is_local)
+            orig_paths = mltable_dict.get(_PATHS_KEY)  # keep relative local file paths
+            mltable_dict = _make_all_paths_absolute(mltable_dict, base_path)
             mltable_loaded = MLTable._create_from_dict(mltable_dict=mltable_dict, orig_paths=orig_paths)
             workspace_context = _parse_workspace_context_from_longform_uri(uri)
             mltable_loaded._workspace_context = workspace_context
             _LoggerFactory.trace(_get_logger(), "load", workspace_context)
             return mltable_loaded
         except Exception as ex:
             if hasattr(activityLogger, ACTIVITY_INFO_KEY):
@@ -487,49 +486,43 @@
             if _PERMISSION_DENIED_ERROR_MSG in ex.args[0]:
                 raise ValueError(ex.args[0])
             raise
 
 
 @track(_get_logger, custom_dimensions={'app_name': _APP_NAME})
 def from_delimited_files(paths, header='all_files_same_headers', delimiter=",", support_multi_line=False,
-                         empty_as_string=False, encoding='utf8', include_path_column=False,
-                         infer_column_types=True):
+                         empty_as_string=False, encoding='utf8', include_path_column=False, infer_column_types=True):
     """
-    Creates an MLTable from given list of delimited files.
+    Creates a MLTable from the given list of delimited files.
 
     .. remarks::
 
         There must be a valid paths string.
 
         .. code-block:: python
 
             # load mltable from local delimited file
             from mltable import from_delimited_files
-            paths = '[{'file': "./samples/mltable_sample/sample_data.csv"}]'
+            paths = [{"file": "./samples/mltable_sample/sample_data.csv"}]
             mltable = from_delimited_files(paths)
 
-    :param paths: paths supports files or folders type with local or cloud path
-    :type paths: list
-    :param header: how column headers are handled when reading from files,
-                   options specified using an enum value of
-                   :class:`mltable.PromoteHeadersBehavior`, defaults to
-                   `all_files_same_header`
-    :type header: Union[str, mltable.MLTablePromoteHeadersBehavior]
+    :param paths: Paths supports files or folders with local or cloud paths. Relative local file paths are assumed to be
+        relative to the current working directory. If the parent directory a local file path is relative to is not the
+        current working directory, instead recommend passing that path as a absolute file path.
+    :type paths: list[dict[str, str]]
+    :param header: How column headers are handled when reading from files. Options specified using the enum
+        :class:`mltable.MLTableHeaders`. Supported headers are 'no_header', 'from_first_file',
+        'all_files_different_headers', and 'all_files_same_headers'.
+    :type header: typing.Union[str, mltable.MLTableHeaders]
     :param delimiter: separator used to split columns
     :type delimiter: str
-    :param support_multi_line: By default (support_multi_line=False), all
-                               line breaks, including those in quoted field
-                               values, will be interpreted as a record break.
-                               Reading data this way is faster and more
-                               optimized for parallel execution on multiple
-                               CPU cores. However, it may result in silently
-                               producing more records with misaligned field
-                               values. This should be set to True when the
-                               delimited files are known to contain quoted
-                               line breaks.
+    :param support_multi_line: If False, all line breaks, including those in quoted field values, will be interpreted
+        as a record break. Reading data this way is faster and more optimized for parallel execution on multiple CPU
+        cores. However, it may result in silently producing more records with misaligned field values. This should be
+        set to True when the delimited files are known to contain quoted line breaks.
 
         .. remarks::
 
             Given this csv file as example, the data will be read differently
             based on support_multi_line.
 
                 A,B,C
@@ -552,67 +545,56 @@
                 # to handle quoted line breaks
                 mltable = from_delimited_files(path, support_multi_line=True)
                 print(mltable.to_pandas_dataframe())
                 #      A       B   C
                 #  0  A1      B1  C1
                 #  1  A2  B\\r\\n2  C2
 
-    If `empty_as_string` is True will read empty fields as empty strings, else
-    read as nulls. If True and column contains datetime or numeric data, empty
-    fields still read as nulls.
-
-    Supported file encodings are 'utf8', 'iso88591', 'latin1', 'ascii',
-    'utf16', 'utf32', 'utf8bom' and 'windows1252'.
-
-    `include_path_column` is useful when reading multiple files and you want
-    to know which file a particular record came from, or to keep useful
-    information that may be stored in a file path.
-
     :type support_multi_line: bool
-    :param empty_as_string: how empty fields should be handled
+    :param empty_as_string: How empty fields should be handled. If True will read empty fields as empty strings, else
+        read as nulls. If True and column contains datetime or numeric data, empty fields still read as nulls.
     :type empty_as_string: bool
-    :param encoding: file encoding
-    :type encoding: str
-    :param include_path_column: keep path information as column in MLTable
+    :param encoding: Specifies the file encoding using the enum :class:`mltable.MLTableFileEncoding`. Supported file
+        encodings are 'utf8', 'iso88591', 'latin1', 'ascii', 'utf16', 'utf32', 'utf8bom' and 'windows1252'.
+    :type encoding: typing.Union[str, mltable.MLTableFileEncoding]
+    :param include_path_column: Keep path information as a column in the MLTable, is useful when reading multiple files
+        and you want to know which file a particular record came from, or to keep useful information that may be stored
+        in a file path.
     :type include_path_column: bool
-    :param infer_column_types: If true, automatically infers all column types. If false, leaves columns as strings. If
+    :param infer_column_types: If True, automatically infers all column types. If False, leaves columns as strings. If
         a dictionary, represents columns whose types are to be set to given types (with all other columns being
         inferred). The dictionary may contain a key named `sample_size` mapped to a positive integer number,
         representing the number of rows to use for inferring column types. The dictionary may also contain a key named
         `column_type_overrides` mapped dictionary. Each key in the dictionary is either a string representing a column
         name or a tuple of strings representing a group of column names. Each value is either a string (one of
-        'boolean', 'string', 'float', 'int', or 'stream_info') or a `mltable.DataType`. If an empty dictionary is
-        given, assumed to be True. Defaults to True.
+        'boolean', 'string', 'float', 'int', or 'stream_info') or a :class:`mltable.DataType`. If an empty dictionary
+        is given, assumed to be True. Defaults to True.
 
         .. remarks::
 
             An example of how to format `infer_column_types`.
 
             .. code-block:: python
 
                 from mltable import from_delimited_files
 
                 # default behavior: support_multi_line=False
                 mltable = from_delimited_files(paths, infer_column_types={
                     'sample_size': 100,
-                    'column_type_overrides: {
+                    'column_type_overrides': {
                         'colA': 'boolean'
                         ('colB', 'colC'): DataType.to_int()
                     }
                 })
 
-    :type infer_column_types: Union[bool, dict[str, Union[str, dict[Union[Tuple[str], str], mltable.DataType]]]
-    :return: MLTable object
-    :return: MLTable
+    :type infer_column_types:
+        typing.Union[bool, dict[str, typing.Union[str, dict[typing.Union[typing.Tuple[str], str], mltable.DataType]]]
+    :return: MLTable instance
     :rtype: mltable.MLTable
     """
-    mltable = from_paths(paths)
-    header = MLTableHeaders._parse(header)
-    encoding = MLTableFileEncoding._parse(encoding)
-
     if not isinstance(infer_column_types, (bool, dict)):
         raise ValueError(
             '`infer_column_types` must be a bool or a dictionary.')
 
     if isinstance(infer_column_types, dict):
         if not infer_column_types:
             infer_column_types = True
@@ -642,22 +624,24 @@
                                      'the values in its dictionary value must be supported strings or '
                                      '`mltable.DataType`s.')
 
                 overrides.append({'columns': k, 'column_type': v._arguments})
 
             infer_column_types['column_type_overrides'] = overrides
 
-    return mltable._add_transformation_step(_READ_DELIMITED_KEY,
-                                            {'delimiter': delimiter,
-                                             'header': header.name,
-                                             'support_multi_line': support_multi_line,
-                                             'empty_as_string': empty_as_string,
-                                             'encoding': encoding.name,
-                                             'include_path_column': include_path_column,
-                                             'infer_column_types': infer_column_types})
+    header = MLTableHeaders._parse(header)
+    encoding = MLTableFileEncoding._parse(encoding)
+    return from_paths(paths)._add_transformation_step(_READ_DELIMITED_KEY,
+                                                      {'delimiter': delimiter,
+                                                       'header': header.name,
+                                                       'support_multi_line': support_multi_line,
+                                                       'empty_as_string': empty_as_string,
+                                                       'encoding': encoding.name,
+                                                       'include_path_column': include_path_column,
+                                                       'infer_column_types': infer_column_types})
 
 
 @track(_get_logger, custom_dimensions={'app_name': _APP_NAME})
 def from_parquet_files(paths, include_path_column=False):
     """
     Create the MLTable from the given list of parquet files.
 
@@ -665,79 +649,72 @@
 
         There must be a valid paths dictionary
 
         .. code-block:: python
 
             # load mltable from local parquet paths
             from mltable import from_parquet_files
-            paths = '[{'file': "./samples/mltable_sample/sample.parquet"}]'
+            paths = [{'file': './samples/mltable_sample/sample.parquet'}]
             mltable = from_parquet_files(paths)
 
-    `include_path_column` is useful when reading multiple files and you want
-    to know which file a particular record came from, or to keep useful
-    information that may be stored in a file path.
-
-    :param paths: paths supports files or folders type with local or cloud path
-    :type paths: list
-    :param include_path_column: if True keeps path information as column
+    :param paths: Paths supports files or folders with local or cloud paths. Relative local file paths are assumed to be
+        relative to the current working directory. If the parent directory a local file path is relative to is not the
+        current working directory, instead recommend passing that path as a absolute file path.
+    :type paths: list[dict[str, str]]
+    :param include_path_column: Keep path information as a column, useful when reading multiple files and you want
+        to know which file a particular record came from, or to keep useful information that may be stored in a file
+        path.
     :type include_path_column: bool
-    :return: MLTable
+    :return: MLTable instance
     :rtype: mltable.MLTable
     """
-    mltable = from_paths(paths)
-    return mltable._add_transformation_step('read_parquet', {"include_path_column": include_path_column})
+    return from_paths(paths)._add_transformation_step('read_parquet', {"include_path_column": include_path_column})
 
 
 @track(_get_logger, custom_dimensions={'app_name': _APP_NAME})
 def from_json_lines_files(paths, invalid_lines="error", encoding="utf8", include_path_column=False):
     """
-    Create the MLTable from the given list of JSON file paths.
+    Create a MLTable from the given list of JSON file paths.
 
     .. remarks::
 
         There must be a valid paths dictionary
 
         .. code-block:: python
 
-            # load mltable from local parquet paths
+            # load mltable from local JSON paths
             from mltable import from_json_lines_files
-            paths = '[{'file': "./samples/mltable_sample/sample_data.jsonl"}]'
+            paths = [{'file': './samples/mltable_sample/sample_data.jsonl'}]
             mltable = from_json_lines_files(paths)
 
-    `include_path_column` is useful when reading multiple files and you want
-    to know which file a particular record came from, or to keep useful
-    information that may be stored in a file path.
-
-    Supported file encodings are 'utf8', 'iso88591', 'latin1', 'ascii',
-    'utf16', 'utf32', 'utf8bom' and 'windows1252'.
-
-    :param paths: paths supports files or folder type with local or cloud path
-    :type paths: list
-    :param invalid_lines: How to handle lines that are invalid JSON. it can be 'drop' or 'error'.
-        If its 'drop', it just drop invalid lines, otherwise it will fail. Default to error.
+    :param paths: Paths supports files or folders with local or cloud paths. Relative local file paths are assumed to be
+        relative to the current working directory. If the parent directory a local file path is relative to is not the
+        current working directory, instead recommend passing that path as a absolute file path.
+    :type paths: list[dict[str, str]]
+    :param invalid_lines: How to handle lines that are invalid JSON, ct can be 'drop' or 'error'.
+        If its 'drop', it just drop invalid lines, otherwise it will fail.
     :type invalid_lines: str
-    :param encoding: Specify the file encoding. Supported encodings are 'utf8', 'iso88591', 'latin1', 'ascii',
-        'utf16', 'utf32', 'utf8bom' and 'windows1252'
-    :type encoding: str
-    :param include_path_column: keep path information as acolumn
+    :param encoding: Specifies the file encoding using the enum :class:`mltable.MLTableFileEncoding`. Supported file
+        encodings are 'utf8', 'iso88591', 'latin1', 'ascii', 'utf16', 'utf32', 'utf8bom' and 'windows1252'.
+    :type encoding: typing.Union[str, mltable.MLTableFileEncoding]
+    :param include_path_column: Keep path information as a column, useful when reading multiple files and you want
+        to know which file a particular record came from, or to keep useful information that may be stored in a file
+        path.
     :type include_path_column: bool
     :return: MLTable
     :rtype: mltable.MLTable
     """
-    mltable = from_paths(paths)
-
     if invalid_lines not in ['error', 'drop']:
-        raise ValueError(
-            "Invalid value for invalid_lines, the supported values are ['error', 'drop']")
+        raise ValueError("Invalid value for invalid_lines, the supported values are ['error', 'drop']")
 
     encoding = MLTableFileEncoding._parse(encoding)
-    return mltable._add_transformation_step(_READ_JSON_KEY,
-                                            {"invalid_lines": invalid_lines,
-                                             "encoding": encoding.name,
-                                             "include_path_column": include_path_column})
+    return from_paths(paths)._add_transformation_step(_READ_JSON_KEY,
+                                                     {"invalid_lines": invalid_lines,
+                                                      "encoding": encoding.name,
+                                                      "include_path_column": include_path_column})
 
 
 @track(_get_logger, custom_dimensions={'app_name': _APP_NAME})
 def from_paths(paths):
     """
     Create the MLTable from the given paths.
 
@@ -752,34 +729,30 @@
             tbl = from_paths([{'file': "./samples/mltable_sample"}])
 
             # load mltable from cloud paths
             from mltable import load
             tbl = from_paths(
                 [{'file': "https://<blob-storage-name>.blob.core.windows.net/<path>/sample_file"}])
 
-
-    :param paths: paths supports file or folder type with local or cloud path
-    :type paths: list
-    :return: MLTable
+    :param paths: Paths supports files or folders with local or cloud paths. Relative local file paths are assumed to be
+        relative to the current working directory. If the parent directory a local file path is relative to is not the
+        current working directory, instead recommend passing that path as a absolute file path.
+    :type paths: list[dict[str, str]]
+    :return: MLTable instance
     :rtype: mltable.MLTable
     """
-    original_path = copy.deepcopy(paths)
-    mltable_yaml_dict = {_PATHS_KEY: paths}
-    for path_dict in mltable_yaml_dict[_PATHS_KEY]:
-        for path_prop, path in path_dict.items():
-            path_type, local_path, _ = _parse_path_format(path)
-            if path_type == _PathType.local and not local_path.startswith('file://'):
-                path_dict[path_prop] = 'file://' + os.path.abspath(local_path)
+    mltable_yaml_dict = _make_all_paths_absolute({_PATHS_KEY: paths}, base_path=os.getcwd())
     _validate(mltable_yaml_dict)
-    return MLTable._create_from_dict(mltable_dict=mltable_yaml_dict, orig_paths=original_path)
+    return MLTable._create_from_dict(mltable_dict=mltable_yaml_dict, orig_paths=paths)
 
 
 @track(_get_logger, custom_dimensions={'app_name': _APP_NAME})
 def from_delta_lake(delta_table_uri, timestamp_as_of=None, version_as_of=None, include_path_column=False):
-    """Creates an MLTable object to read in Parquet files from delta lake table.
+    """
+    Creates an MLTable object to read in Parquet files from delta lake table.
 
     .. remarks::
 
         **from_delta_lake** creates an MLTable object which defines the operations to
         load data from delta lake folder into tabular representation.
 
         For the data to be accessible by Azure Machine Learning, `path` must point to the delta table directory
@@ -807,19 +780,19 @@
     :type delta_table_uri: str
     :param timestamp_as_of: datetime string in RFC-3339/ISO-8601 format to use to read in matching parquet files
         from a specific point in time.
         ex) "2022-10-01T00:00:00Z", "2022-10-01T00:00:00+08:00", "2022-10-01T01:30:00-08:00"
     :type timestamp_as_of: string
     :param version_as_of: integer version to use to read in a specific version of parquet files.
     :type version_as_of: int
-    :param include_path_column: Boolean to keep path information as column in the mltable. Defaults to False.
-        This is useful when reading multiple files, and want to know which file a particular record
-        originated from, or to keep useful information in file path.
+    :param include_path_column: Keep path information as a column, useful when reading multiple files and you want
+        to know which file a particular record came from, or to keep useful information that may be stored in a file
+        path.
     :type include_path_column: bool
-    :return: MLTable object
+    :return: MLTable instance
     :rtype: mltable.MLTable
     """
     if timestamp_as_of and version_as_of:
         raise KeyError("Both timestamp_as_of and version_as_of parameters were provided, but only one of version_as"
                        "_of or timestamp_as_of can be specified.")
 
     if timestamp_as_of:
@@ -860,15 +833,21 @@
         """
         Returns all the information associated with MLTable as a YAML-style
         string representation.
 
         :return: string representation of this MLTable
         :rtype: str
         """
-        return self._dataflow.to_yaml_string()
+        self._check_loaded()
+        # _dataflow.to_yaml_string() serializes Serde units (anonymous value containing no data) as nulls
+        # this results in nested fields with empty values being serialized with nulls as value.
+        mltable_yaml_str = self._dataflow.to_yaml_string()
+        mltable_yaml_dict = yaml.safe_load(mltable_yaml_str)
+        mltable_yaml_helper = MLTableYamlCleaner(mltable_yaml_dict=mltable_yaml_dict)
+        return str(mltable_yaml_helper)
 
     @track(_get_logger, custom_dimensions={'app_name': _APP_NAME})
     def validate(self):
         """
         Validates if this MLTable's data can be loaded, requires the MLTable's
         data source(s) to be accessible from the current compute.
 
@@ -1027,15 +1006,15 @@
 
         mltable_yaml_str = new_mltable._dataflow.to_yaml_string()
         try:
             download_records = to_pyrecords_with_preppy('MLTable._download', mltable_yaml_str)
             actual_download_list = _get_and_validate_download_list(download_records, ignore_not_found, _get_logger())
             return actual_download_list
         except Exception as ex:
-            _classify_known_user_error_from_rslex(ex.args[0])
+            _classify_known_user_error(ex.args[0])
 
     @track(_get_logger, custom_dimensions={'app_name': _APP_NAME})
     def _with_partition_size(self, min_batch_size):
         """
         Update a transformation step to use the partition size of defined. Support delimited files and json files.
 
         :param min_batch_size: minimum batch size to partition the data
@@ -1054,15 +1033,14 @@
         for key in [_READ_DELIMITED_KEY, _READ_JSON_KEY]:
             if key in mltable_yaml_dict[_TRANSFORMATIONS_KEY][0]:  # TODO ideally this should be in Rust
                 mltable_yaml_dict[_TRANSFORMATIONS_KEY][0][key]['partition_size'] = min_batch_size
                 return MLTable._create_from_dict(mltable_dict=mltable_yaml_dict, orig_paths=orig_paths)
 
         raise _WITH_PARITION_SIZE_REQUIRED_TRANSFORMATIONS_ERROR
 
-
     def to_pandas_dataframe(self):
         """
         Load all records from the paths specified in the MLTable file into a
         Pandas DataFrame.
 
         .. remarks::
 
@@ -1092,20 +1070,15 @@
                 try:
                     mltable_yaml_str = self._dataflow.to_yaml_string()
                     dataframe_reader = get_dataframe_reader()
                     df = dataframe_reader.to_pandas_dataframe(mltable_yaml_str)
                     return df
                 except Exception as e:
                     message = e.args[0]
-                    if "Python expression parse error" in message:
-                        raise ValueError(
-                            "Not a valid python expression in filter") from e
-                    elif _PERMISSION_DENIED_ERROR_MSG in e.args[0]:
-                        raise ValueError(e.args[0])
-                    raise
+                    _classify_known_user_error(message, e)
             except Exception as e:
                 if hasattr(activityLogger, ACTIVITY_INFO_KEY):
                     activityLogger.activity_info['error_code'] = getattr(
                         e, ERROR_CODE_KEY, '')
                     activityLogger.activity_info['message'] = getattr(
                         e, COMPLIANT_MESSAGE_KEY, str(e))
                     activityLogger.activity_info['outer_error_code'] = getattr(
@@ -1567,31 +1540,35 @@
                                                                "probability_lower_bound": percent,
                                                                "seed": seed}})
         return split_a, split_b
 
     @track(_get_logger, custom_dimensions={'app_name': _APP_NAME})
     def save(self, path=None, overwrite=True):
         """
-        Save this MLTable as a MLTable YAML file to the given local directory path. If a path is not given, defaults
-        to the current working directory. If the path is not absolute, makes it absolute. If the path does not exist,
-        creates it.
+        Save this MLTable as a MLTable YAML file to the given local directory path. If `path` is not given, defaults
+        to the current working directory. If `path` is not absolute, it is made absolute. If `path` does not exist,
+        it is created.
 
-        Raises a ValueError if `path` points to a file, or is a directory path already containing an MLTable YAML
+        A ValueError is raised if `path` points to a file, or is a directory path which already contains a MLTable YAML
         file and `overwrite` is set to False.
 
-        If any local file paths are used in this MLTable, recommend setting `path` to a directory such that those file
-        paths are direct descendents of so they remain co-located with the resulting MLTable YAML file. Any directories
+        If any local file paths are used in this MLTable, recommend setting `path` to a directory that those file paths
+        are direct descendents of so they remain co-located to the resulting MLTable YAML file. Any directories
         of co-located file paths that overlap with the save directory path will be removed.
 
         For example if the file path '/tmp/train/data.txt' is used in a MLTable and that MLTable is saved to directory
         '/tmp', since it is co-located with the save directory ('train/data.txt' is under 'tmp') 'tmp' will be removed
         from the file path and the file path will be saved as 'train/data.txt' in the resulting MLTable YAML file.
 
-        If such a path is not given, instead will attempt to create new relative file paths from the original file
-        paths to `path` for files not co-located in `path`.
+        Note that if the MLTable is created programatically with methods like `from_paths()` or
+        `from_read_delimited_files()` with local relative paths, the MLTable directory path is assumed to be the
+        current working directory. Save if saving such the curmethod is used to save a MLTable for the first
+
+        If such a directory path is not given, instead will attempt to create new relative file paths from the original
+        file paths to `path` for files not co-located in `path`.
 
         For example if the file path '/tmp/train/data.txt' is used in a MLTable and that MLTable is saved to directory
         '/tmp2', since it is NOT co-located with the save directory the file path will be replaced with
         '../tmp/train/data.txt' in the resulting MLTable YAML file.
 
         However if the save directory & a file path are on different file mounts, will leave file path untouched.
 
@@ -1753,15 +1730,15 @@
                     pass
 
             is_empty = not any(files or dirnames for _,
                                dirnames, files in os.walk(path))
             return (os.path.abspath(path), is_empty)
 
         mltable_yaml_str = self._dataflow.to_yaml_string()
-        hash_object = hashlib.md5(mltable_yaml_str.encode())
+        hash_object = hashlib.md5(mltable_yaml_str.encode()).hexdigest()
         dataflow_in_memory_uri = f'inmemory://dataflow/{hash_object}'
         ensure_rslex_environment()
         from azureml.dataprep.rslex import add_in_memory_stream
         add_in_memory_stream(dataflow_in_memory_uri, mltable_yaml_str)
 
         dataflow_in_memory_uri_encoded = urllib.parse.quote(dataflow_in_memory_uri.encode('utf8'), safe='')
 
@@ -1808,15 +1785,15 @@
             allow_fallback_to_clex = False
 
         mltable_yaml_str = self._dataflow.to_yaml_string()
         try:
             _execute('mltable._execute', mltable_yaml_str, force_clex=force_clex,
                      allow_fallback_to_clex=allow_fallback_to_clex)
         except Exception as ex:
-            _classify_known_user_error_from_rslex(ex.args[0])
+            _classify_known_user_error(ex.args[0])
 
 
 class Metadata:
     """
     Class that maps to the metadata section of the MLTable.
 
     Supports the getting & adding of arbritrary metadata properties.
```

## mltable/_aml_utilities/_aml_rest_client_helper.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 """Contains helper methods for asset service REST APIs."""
 
+import re
 import os
 from azureml.dataprep.api._loggerfactory import _LoggerFactory
 from ._restclient._azure_machine_learning_workspaces import AzureMachineLearningWorkspaces as rest_client
 from ._azureml_token_authentication import AzureMLTokenAuthentication
 
 # ENV VARIABLE KEY FROM RUN CONTEXT
 HISTORY_SERVICE_ENDPOINT_KEY = 'AZUREML_SERVICE_ENDPOINT'
@@ -78,15 +79,15 @@
 
 def _get_aml_service_base_url(location=None):
     host_env = os.environ.get(HISTORY_SERVICE_ENDPOINT_KEY)
 
     # default to master
     if host_env is None:
         if location is None or location == 'centraluseuap':
-            host_env = 'https://master.api.azureml-test.ms'
+            host_env = 'https://int.api.azureml-test.ms'
         else:
             host_env = F'https://{location}.api.azureml.ms'
 
     return host_env
 
 
 def _get_rest_client(storage_options, auth):
@@ -113,14 +114,23 @@
         return rest_client.data_version.get_by_asset_id(
             storage_options[STORAGE_OPTION_KEY_AZUREML_SUBSCRIPTION],
             storage_options[STORAGE_OPTION_KEY_AZUREML_RESOURCEGROUP],
             storage_options[STORAGE_OPTION_KEY_AZUREML_WORKSPACE],
             {'value': asset_id},
         )
 
+    # parse asset_id for workspace location
+    legacy_dataset_asset_id_pattern = re.compile(
+        r'^azureml://locations/([^\/]+)/workspaces/([^\/]+)/data/([^\/]+)/versions/(.*)',
+        re.IGNORECASE)
+    legacy_dataset_asset_id_match = legacy_dataset_asset_id_pattern.match(asset_id)
+    if not legacy_dataset_asset_id_match:
+        raise ValueError(f'Missing required workspace location information in: `{asset_id}`')
+    storage_options[STORAGE_OPTION_KEY_AZUREML_LOCATION] = legacy_dataset_asset_id_match.group(1)
+
     # this logic is only for enabling e2e test
     from azure.identity import AzureCliCredential
     auth = AzureCliCredential()
     client = _get_rest_client(storage_options, auth)
     asset = client.data_version.get_by_asset_id(
         storage_options[STORAGE_OPTION_KEY_AZUREML_SUBSCRIPTION],
         storage_options[STORAGE_OPTION_KEY_AZUREML_RESOURCEGROUP],
```

## mltable/schema/MLTable.json

### Pretty-printed

 * *Similarity: 0.9999999996083064%*

 * *Differences: {"'properties'": "{'transformations': {'items': {'oneOf': {7: {'properties': {'read_json_lines': "*

 * *                 "{'properties': {'encoding': {'enum': {insert: [(1, 'utf-8')]}}}}}}}}}}"}*

```diff
@@ -473,14 +473,15 @@
                                 "additionalProperties": false,
                                 "description": "Reads JSON lines file from the provided paths using the defined options.",
                                 "properties": {
                                     "encoding": {
                                         "default": "utf8",
                                         "enum": [
                                             "utf8",
+                                            "utf-8",
                                             "iso88591",
                                             "latin1",
                                             "ascii",
                                             "utf16",
                                             "utf32",
                                             "utf8bom",
                                             "windows1252"
```

## mltable/tests/helper_functions.py

```diff
@@ -1,10 +1,11 @@
 import copy
 import os.path
 
+import tempfile
 import yaml
 from azureml.dataprep import _read_yaml
 
 from mltable.mltable import load
 
 
 def mltable_was_loaded(mltable):
@@ -15,17 +16,32 @@
 
 
 def can_load_mltable(uri, storage_options=None):
     try:
         mltable = load(uri=uri, storage_options=storage_options)
     except Exception as e:
         assert False, f'failed to load MLTable, got error [{type(e)}: {e}]'
+
+    _test_save_load_round_trip(mltable, storage_options)
     return mltable_was_loaded(mltable)
 
 
+def _test_save_load_round_trip(mltable, storage_options):
+    with tempfile.TemporaryDirectory() as temp_dir:
+        mltable.save(temp_dir)
+        loaded_mltable = load(temp_dir, storage_options=storage_options)
+        original_df = mltable.to_pandas_dataframe()
+        loaded_df = loaded_mltable.to_pandas_dataframe()
+        assert original_df is not None
+        assert loaded_df is not None
+        assert original_df.equals(loaded_df)
+        # test that the string representation remains the same after roundtrip
+        assert str(mltable) == str(loaded_mltable)
+
+
 def mltable_as_dict(mltable):
     """
     Given a MLTable, returns it's underlying Dataflow (added transformation steps, metadata, etc.)
     as a dictionary
     """
     return yaml.safe_load(mltable._dataflow.to_yaml_string())
```

## mltable/tests/test_from_delta_lake.py

```diff
@@ -1,9 +1,9 @@
 import os
-from mltable.mltable import from_delta_lake
+from mltable.mltable import from_delta_lake, load
 from .helper_functions import can_load_mltable
 import pandas as pd
 import pytest
 
 
 @pytest.mark.mltable_sdk_unit_test
 class TestFromDeltaLake:
@@ -168,7 +168,37 @@
         t3 = "2021-08-09T01:30:00.238016Z"
         mltable_t3 = from_delta_lake(
             delta_table_path, timestamp_as_of=t3, include_path_column=True)
         df_t3 = mltable_t3.to_pandas_dataframe()
         print(df_t3.to_string())
         assert df_t3.shape == (5, 2)
         assert df_t3["id"].equals(pd.Series([5, 6, 7, 8, 9]))
+
+
+@pytest.mark.mltable_sdk_unit_test
+class TestFromDeltaLakeUserErrors:
+    def test_from_local_both_version_and_timestamp(self, get_dir_folder_path):
+        cwd = get_dir_folder_path
+        mltable_path = os.path.join(cwd, "data/mltable/delta-table-both-version-and-timestamp/")
+        with pytest.raises(ValueError) as excinfo:
+            mltable = load(mltable_path)
+            mltable.to_pandas_dataframe()
+        assert "Only one of version or timestamp can be specified but not both." in str(excinfo.value)
+
+    def test_from_local_unable_to_find_metadata(self, get_dir_folder_path):
+        cwd = get_dir_folder_path
+        os.chdir(cwd)
+        # test using a non delta table MLTable directory
+        delta_table_path = "data/mltable/mltable_folder"
+        with pytest.raises(ValueError) as excinfo:
+            mltable = from_delta_lake(delta_table_path, version_as_of=0)
+            mltable.to_pandas_dataframe()
+        assert "Unable to find any delta table metadata" in str(excinfo.value)
+
+    def test_from_local_invalid_table_version(self, get_dir_folder_path):
+        cwd = get_dir_folder_path
+        os.chdir(cwd)
+        delta_table_path = "data/mltable/delta-table"
+        with pytest.raises(ValueError) as excinfo:
+            mltable = from_delta_lake(delta_table_path, version_as_of=100000)
+            mltable.to_pandas_dataframe()
+        assert "Error when opening delta table: Invalid table version: 100000" in str(excinfo.value)
```

## mltable/tests/test_mltable_inner_functions.py

```diff
@@ -229,15 +229,15 @@
         assert not _path_is_current_directory_variant(non_base_dir)
 
 
 @pytest.mark.mltable_sdk_unit_test
 class TestMLTableMakeAllPathsAbsolute:
     def run_no_change(self, path, base_path, is_local=False):
         mltable_yaml_dict = [{'paths': [{'file': path}]}]
-        result = _make_all_paths_absolute(copy.deepcopy(mltable_yaml_dict), base_path, is_local)
+        result = _make_all_paths_absolute(copy.deepcopy(mltable_yaml_dict), base_path)
         assert result is not mltable_yaml_dict
         assert result == mltable_yaml_dict
 
     def test_path_starts_with_file_header(self):
         self.run_no_change('file:///home/user/files/file.csv', '/swp/thing')
 
     def test_absolute_path(self):
@@ -245,54 +245,54 @@
 
     def test_non_local_path(self):
         self.run_no_change('https://www.github.com/repo/test_csv', '/swp/thing')
 
     def test_cloud_path(self):
         self.run_no_change('https://dprepdata.blob.core.windows.net/demo/Titanic2.csv', '/mltable/dirc/path')
 
-    def run_append_base_path(self, *paths, base_path='.', is_local=False):
+    def run_append_base_path(self, *paths, base_path='.'):
         base_path = os.path.abspath(base_path)
         mltable_yaml_dict = {'paths': [{'file': path} for path in paths]}
         # TODO remove copy when mutation issue fixed
-        result = _make_all_paths_absolute(copy.deepcopy(mltable_yaml_dict), base_path, is_local)
+        result = _make_all_paths_absolute(copy.deepcopy(mltable_yaml_dict), base_path)
         exp_result = {'paths': [
-            {'file': ('file://' if is_local else '') + os.path.join(base_path, os.path.normpath(path))}
+            {'file': 'file://' + os.path.join(base_path, os.path.normpath(path))}
             for path in paths]}
         assert len(result['paths']) == len(exp_result['paths'])
         for path_dict in result['paths']:
             assert path_dict in exp_result['paths']
 
     def test_local_happy_relative_paths(self, get_data_folder_path):
         base_path = os.path.join(get_data_folder_path, 'mltable_relative')
-        self.run_append_base_path('Titanic2.csv', './subfolder/Titanic2.csv', base_path=base_path, is_local=False)
+        self.run_append_base_path('Titanic2.csv', './subfolder/Titanic2.csv', base_path=base_path)
 
     def test_non_absolute_local_paths_made_absolute(self, get_data_folder_path):
         base_path = os.path.join(get_data_folder_path, 'mltable_relative')
-        self.run_append_base_path('Titanic2.csv', './subfolder/Titanic2.csv', base_path=base_path, is_local=True)
+        self.run_append_base_path('Titanic2.csv', './subfolder/Titanic2.csv', base_path=base_path)
 
     def test_non_absolute_basepath(self):
         self.run_append_base_path(
-            'Titanic2.csv', './subfolder/Titanic2.csv', base_path='mltable_relative', is_local=True)
+            'Titanic2.csv', './subfolder/Titanic2.csv', base_path='mltable_relative')
 
     def test_cwd_basepath(self):
         self.run_append_base_path(
-            'Titanic2.csv', './subfolder/Titanic2.csv', base_path='.', is_local=True)
+            'Titanic2.csv', './subfolder/Titanic2.csv', base_path='.')
 
     def test_data_asset_uri_basepath(self):
         base_path = 'azureml://subscriptions/test/resourcegroups/rg/' \
                     'providers/Microsoft.MachineLearningServices/workspaces/ws/data/d/versions/1'
-        self.run_append_base_path('Titanic2.csv', './subfolder/Titanic2.csv', base_path=base_path, is_local=False)
+        self.run_append_base_path('Titanic2.csv', './subfolder/Titanic2.csv', base_path=base_path)
 
     def test_cloud_basepath(self):
         base_path = 'https://www.github.com/my/mltable/repo'
-        self.run_append_base_path('Titanic2.csv', './subfolder/Titanic2.csv', base_path=base_path, is_local=False)
+        self.run_append_base_path('Titanic2.csv', './subfolder/Titanic2.csv', base_path=base_path)
 
     def test_legacy_dataset_basepath(self):
         base_path = 'azureml://locations/azure_loc/workspaces/ws/data/d/versions/1'
-        self.run_append_base_path('Titanic2.csv', './subfolder/Titanic2.csv', base_path=base_path, is_local=True)
+        self.run_append_base_path('Titanic2.csv', './subfolder/Titanic2.csv', base_path=base_path)
 
 
 @pytest.mark.mltable_sdk_unit_test_windows
 class TestInnerFunctionsWindowsOnly:
     def test_make_all_paths_absolute_local_relative_path_double_backslash(
             self, get_data_folder_path):
 
@@ -301,16 +301,16 @@
             'paths': [{'file': '.\\Titanic2.csv'}, {'file': '..\\Titanic2.csv'}],
             'transformations': [{
                 'read_delimited': {
                     'delimiter': ',', 'encoding': 'ascii', 'empty_as_string': False}}
             ]
         }
 
-        exp_paths = [os.path.normpath(os.path.join(base_path, 'Titanic2.csv')),
-                     os.path.normpath(os.path.join(base_path, '..\\Titanic2.csv'))]
+        exp_paths = ['file://' + os.path.normpath(os.path.join(base_path, 'Titanic2.csv')),
+                     'file://' + os.path.normpath(os.path.join(base_path, '..\\Titanic2.csv'))]
 
         yaml_with_absolute_paths = _make_all_paths_absolute(yaml_dict, base_path)
         for path_dict, exp_path in zip(yaml_with_absolute_paths['paths'], exp_paths):
             for _, path in path_dict.items():
                 assert path == exp_path
 
     def test_make_all_paths_absolute_local_relative_path_no_initial_separator(
@@ -321,16 +321,16 @@
         yaml_dict = {
             'paths': [{'file': 'Titanic2.csv'}, {'file': 'subfolder\\Titanic2.csv'}],
             'transformations': [{
                 'read_delimited': {
                     'delimiter': ',', 'encoding': 'ascii', 'empty_as_string': False}}
             ]
         }
-        exp_paths = [os.path.join(base_path, 'Titanic2.csv'),
-                     os.path.join(base_path, 'subfolder\\Titanic2.csv')]
+        exp_paths = ['file://' + os.path.join(base_path, 'Titanic2.csv'),
+                     'file://' + os.path.join(base_path, 'subfolder\\Titanic2.csv')]
 
         yaml_with_absolute_paths = _make_all_paths_absolute(yaml_dict, base_path)
         for path_dict, exp_path in zip(yaml_with_absolute_paths['paths'], exp_paths):
             for _, path in path_dict.items():
                 assert path == exp_path
 
     def test_make_all_paths_absolute_prior_loaded_local_path_with_diff_directory(self):
```

## mltable/tests/test_mltable_load.py

```diff
@@ -1,11 +1,11 @@
 import os
 
 import pytest
-from azureml.dataprep.api.mltable._mltable_helper import _read_yaml
+from azureml.dataprep.api.mltable._mltable_helper import _read_yaml, UserErrorException
 
 from mltable.mltable import load
 from .helper_functions import can_load_mltable, get_invalid_mltable, get_mltable_and_dicts, list_of_dicts_equal, \
     mltable_as_dict
 
 
 @pytest.mark.mltable_sdk_unit_test
@@ -69,19 +69,25 @@
 
     def test_load_mltable_with_arbitrary_metadata(self, get_data_folder_path):
         mltable_dirc = get_data_folder_path
         mltable_path = os.path.join(mltable_dirc, 'mltable_arb_metadata')
         can_load_mltable(mltable_path)
 
     def test_load_mltable_with_invalid_url(self):
-        with pytest.raises(ValueError) as excinfo:
+        with pytest.raises(UserErrorException) as excinfo:
             mltable_url = 'https://raw.githubusercontent.com/microsoft/arcticseals/master/data/test.csv'
             load(mltable_url)
         assert "Not able to find MLTable file" in str(excinfo.value)
 
+    def test_load_mltable_pattern_invalid_file_path(self, get_data_folder_path):
+        data_folder_path = os.path.join(get_data_folder_path, 'mltable_pattern')
+        with pytest.raises(ValueError) as excinfo:
+            can_load_mltable(uri=data_folder_path)
+        assert "Invalid argument \"file-path\"" in str(excinfo.value)
+
 
 @pytest.mark.mltable_sdk_unit_test_windows
 class TestMLTableLoadWindowsOnly:
     def test_load(self, get_data_folder_path):
         mltable_dirc_path = get_data_folder_path
         mltable_path = os.path.join(mltable_dirc_path, 'mltable_windows')
         og_mltable, og_mltable_yaml_dict, og_mltable_yaml_file_dict = get_mltable_and_dicts(mltable_path)
```

## mltable/tests/test_mltable_load_to_pandas.py

```diff
@@ -127,17 +127,17 @@
 
     def test_mltable_filter_datetime(self, get_dir_folder_path):
         cwd = get_dir_folder_path
         exp_path_1 = os.path.normpath(
             os.path.join(cwd, 'data/crime.parquet'))
         paths = [{'file': exp_path_1}]
         mltable = from_parquet_files(paths)
-        filtered_mltable = mltable.filter('Date > datetime(2015, 7, 5)')
+        filtered_mltable = mltable.filter('Date >= datetime(2015, 7, 5, 23)')
         df = mltable_was_loaded(filtered_mltable)
-        assert df.shape == (10, 22)
+        assert df.shape == (5, 22)
 
     def test_mltable_filter_column_invalid_expression(self, get_dir_folder_path):
         cwd = get_dir_folder_path
         exp_path_1 = os.path.normpath(
             os.path.join(cwd, 'data/crime-spring.csv'))
         paths = [{'file': exp_path_1}]
         mltable = from_delimited_files(paths, infer_column_types=False)
```

## mltable/tests/test_validation_and_error_handler.py

```diff
@@ -1,37 +1,37 @@
-from mltable._validation_and_error_handler import _classify_known_user_error_from_rslex, _download_error_handler, \
+from mltable._validation_and_error_handler import _classify_known_user_error, _download_error_handler, \
     _get_and_validate_download_list
 from mltable.mltable import _get_logger
 from azureml.dataprep.native import DataPrepError, StreamInfo
 import pytest
 
 
 @pytest.mark.mltable_sdk_unit_test
 class TestValidationErrorHandler:
-    def test_classify_known_user_error_from_rslex(self):
+    def test_classify_known_user_error(self):
         exception_str_value_error = ["InvalidUriScheme", "StreamError(NotFound)", "DataAccessError(NotFound)",
                                      "No such host is known", "No identity was found on compute"]
 
         exception_str_system_error = ["Microsoft.DPrep.ErrorValues.PythonNumpyDatetimeParseFailure",
                                       "Microsoft.DPrep.ErrorValues.IntegerOverflow",
                                       "Microsoft.DPrep.ErrorValues.UnsupportedPythonObject"]
 
         with pytest.raises(ValueError) as e:
             err_string = 'ExecutionError(StreamError(PermissionDenied(Some(Server failed to authenticate the request'
-            _classify_known_user_error_from_rslex(err_string)
+            _classify_known_user_error(err_string)
         assert err_string in str(e.value)
 
         for val_error in exception_str_value_error:
             with pytest.raises(ValueError) as e:
-                _classify_known_user_error_from_rslex(val_error)
+                _classify_known_user_error(val_error)
             assert val_error in str(e.value)
 
         for sys_error in exception_str_system_error:
             with pytest.raises(SystemError) as e:
-                _classify_known_user_error_from_rslex(sys_error)
+                _classify_known_user_error(sys_error)
             assert sys_error in str(e.value)
 
     def test_download_error_handler(self):
         value_error_list = [('dummyFile1.csv', "Microsoft.DPrep.ErrorValues.SourceFileNotFound"),
                             ('dummyFile2.csv', "Microsoft.DPrep.ErrorValues.SourceFilePermissionDenied"),
                             ('dummyFile3.csv', "Microsoft.DPrep.ErrorValues.InvalidArgument"),
                             ('dummyFile4.csv', "Microsoft.DPrep.ErrorValues.SourcePermissionDenied"),
```

## Comparing `mltable-1.2.0.dist-info/LICENSE.txt` & `mltable-1.3.0.dist-info/LICENSE.txt`

 * *Files identical despite different names*

## Comparing `mltable-1.2.0.dist-info/METADATA` & `mltable-1.3.0.dist-info/METADATA`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mltable
-Version: 1.2.0
+Version: 1.3.0
 Summary: Contains MLTable loading and authoring apis for the mltable package.
 Home-page: https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py
 Author: Microsoft Corp
 License: Proprietary https://aka.ms/azureml-preview-sdk-license 
 Platform: UNKNOWN
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
@@ -19,15 +19,15 @@
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Operating System :: MacOS
 Classifier: Operating System :: Microsoft :: Windows
 Classifier: Operating System :: POSIX :: Linux
 Classifier: Topic :: Scientific/Engineering
 Requires-Python: >=3.6,< 4.0
 Description-Content-Type: text/x-rst
-Requires-Dist: azureml-dataprep[parquet] (<4.10.0a,>=4.9.0a)
+Requires-Dist: azureml-dataprep[parquet] (<4.11.0a,>=4.10.0a)
 Requires-Dist: pyyaml (<7.0.0,>=5.1.0)
 Requires-Dist: jsonschema (<5.0.0,>=4.0.0)
 Requires-Dist: msrest (>=0.6.18)
 Requires-Dist: azure-core (!=1.22.0,<2.0.0,>=1.8.0)
 Requires-Dist: azure-mgmt-core (<2.0.0,>=1.3.0)
 Requires-Dist: python-dateutil (<3.0.0,>=2.7.3)
 Requires-Dist: cryptography (!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<41)
@@ -63,14 +63,19 @@
 
 The official documentation is hosted on [Create a mltable data asset.](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-data-assets?tabs=cli#create-a-mltable-data-asset) 
 
 MLTable artifact’s metadata file is called  MLTable which adheres to the [AzureML MLTable schema](https://learn.microsoft.com/en-us/azure/machine-learning/reference-yaml-mltable). 
 
 # Release History
 
+## 1.3.0 (2023-04-07)
+
+### Features Added
+ - bugfix (user error mapping, mltable save/load roundtrip)
+
 ## 1.2.0 (2023-02-22)
 
 ### Features Added
  - bugfix (mltable save/load, validation schema)
 
 ## 1.1.0 (2023-01-26)
```

## Comparing `mltable-1.2.0.dist-info/RECORD` & `mltable-1.3.0.dist-info/RECORD`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 mltable/__init__.py,sha256=KWXO09yBdXoBfbE56ZFQN72ICn_-XPx_ltjVksTSWgU,937
-mltable/_utils.py,sha256=XbGjs79npfXEUOoC8Uf-KkzjRIA5CpbFJy4LClIp-Yw,3078
-mltable/_validation_and_error_handler.py,sha256=W8XfNNEjUMDTW2xLDuEGcPOSHBtinwezD2ela6fqXdQ,3773
-mltable/mltable.py,sha256=TNrR3wa2PfilV4M9ZN--nObvdkqexLRPgSLX01hjNyA,89910
+mltable/_utils.py,sha256=9lb3CfUI8Luq0euX4DXiBLrETWWtORAnS09MX9Ie5NQ,4193
+mltable/_validation_and_error_handler.py,sha256=gSyVnbPtHUtQJmdx7OTJC5jOI-Dd3UxekaKpbihIkFo,4404
+mltable/mltable.py,sha256=yysbW6JZqczSp_ZhaS30Dd1u89EktuZuDXxEU_ZQAzY,90746
 mltable/_aml_utilities/__init__.py,sha256=JlCCObuOLZyNhIZlsoL51KtFxiY4xKIIzIRDBcdeu6Y,183
-mltable/_aml_utilities/_aml_rest_client_helper.py,sha256=wycU_o9kkzN-V0-HvJ_O2sRdIX8VvsfgG6MGnzVoQ_s,6778
+mltable/_aml_utilities/_aml_rest_client_helper.py,sha256=dB5A_9wDumn31yvXgthwRUoBCrLZ1r6jm8J6G1SUpEw,7321
 mltable/_aml_utilities/_azureml_token_authentication.py,sha256=ixmzyWC4gvT8ia16q3aXjYWH58KYBWycZPZEWEQ2xGw,23222
 mltable/_aml_utilities/_restclient/__init__.py,sha256=38lKUIqL59KqhES7ZGBUGcrELWICWet0VFLxwY4W0fo,893
 mltable/_aml_utilities/_restclient/_azure_machine_learning_workspaces.py,sha256=OwUbiGVcnH-AkIrCkU4S3W_Nrde5-IsricQQVwXZMqE,4218
 mltable/_aml_utilities/_restclient/_configuration.py,sha256=E52K3BmA4ZqAE6oP5VjRK32HsBrl6W9Y1oOsWCJu8Ig,3538
 mltable/_aml_utilities/_restclient/_patch.py,sha256=wuqrJGWK488sJvWwSq6iwPTqil7TPaRadoxE7BMK0tA,1561
 mltable/_aml_utilities/_restclient/_version.py,sha256=72yoX3gRVc4OFrnlCjEq_1cS0FLSIvofYIXtMN1ElvI,495
 mltable/_aml_utilities/_restclient/models.py,sha256=tjqC6v_UMQnzxwfUWjLDMCV7YM7Td__4crr8zzNy4hM,365
@@ -45,26 +45,26 @@
 mltable/_common/chained_identity.py,sha256=1eExz4Ga4oEtrpD7oYcDkRfBgK1HUJidj9T-SsgU4Pw,2393
 mltable/_common/logged_lock.py,sha256=ZIINoMdzt4j-myA1nofPIZN7Gee5vUFU-dBjslFKrAA,933
 mltable/_common/async_utils/__init__.py,sha256=JlCCObuOLZyNhIZlsoL51KtFxiY4xKIIzIRDBcdeu6Y,183
 mltable/_common/async_utils/async_task.py,sha256=F6iilclJAWER2RfJg71LypoQbnNyVSDng2sitvddbtQ,2827
 mltable/_common/async_utils/daemon.py,sha256=SvsUKj-NGExutabI-Vaj6w2vC_XXicf8pLsNwB-8FRs,2329
 mltable/_common/async_utils/task_queue.py,sha256=mP4Ajv_fMH83VHS1yxHfPAJWK_npmWdjLZ-U-z0dLBw,5911
 mltable/_common/async_utils/worker_pool.py,sha256=2KOSfRMzIjrTmJ6y5cMa5mhe0bwoS3ELawGt2EGWWnc,1112
-mltable/schema/MLTable.json,sha256=j3d6AH01LxpZI8JBDnIeuT1MxJX-Hn1q8eW8r_C2Vvc,31813
+mltable/schema/MLTable.json,sha256=T9kp_NOQu_NCYRtSO4uUvnbxunhD1rbv3oUEZQGzvoA,31845
 mltable/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mltable/tests/conftest.py,sha256=647QZtFYv7mKDXbD6nckadaamC5O7YCEb37oG0wDPqs,2129
-mltable/tests/helper_functions.py,sha256=gAe0hiRm9z6WkSTQFHRTeErIcE2oqXxn2gqd-zAIxNc,1454
-mltable/tests/test_from_delta_lake.py,sha256=zyNGdmcH6yMbU9Y3E0_TCnP7EzHH3gDy9kt6V1W9F7E,9825
+mltable/tests/helper_functions.py,sha256=np4dzULX4gywmwr7o3QKTqs-5opIOzBFo4d-aKkA7P8,2120
+mltable/tests/test_from_delta_lake.py,sha256=I4AcJuSMVEsaqYJnFHMjlT-M4GVsQfrYEnMKD15qKUQ,11329
 mltable/tests/test_from_json_lines.py,sha256=jKTEhZa9cQR-za4CFoMCpt2uCTN1lhZdG7XqPjUxW_Q,3968
 mltable/tests/test_mltable_authoring_apis.py,sha256=XaHRFy7NnabRC1dolQOUyf7ippFKC5-QiREZghHK_uY,61415
-mltable/tests/test_mltable_inner_functions.py,sha256=qyuO7M6ceL6tMSrg0lH5JsgJ8eJMDyIPnLa7KFwCFfY,15302
-mltable/tests/test_mltable_load.py,sha256=QaHq8t9DiHhnt1iKK7F97cvqqN4LJYc2xk_2CfkQbzM,4779
-mltable/tests/test_mltable_load_to_pandas.py,sha256=9TL4opdtq8ItoKH8_bQUmU3dQTFJf_idD_yodyB-kPI,9658
+mltable/tests/test_mltable_inner_functions.py,sha256=hjdMDU3D5KyPJrZ7AeXrClulalsy5TpnhvU8taUvLAg,15184
+mltable/tests/test_mltable_load.py,sha256=j-RGFG7D6noFRSPzZEptW98hZ5mEDyqY8WHFhihb8p8,5148
+mltable/tests/test_mltable_load_to_pandas.py,sha256=GcW3uuTGvQFnIq_XBGo9h8CoJ9w_eHrQjwfSaqXHRGk,9662
 mltable/tests/test_mltable_save.py,sha256=uLYJtEjdG4iqwUWyv5jLrQnTJCkVvX1Agfn8UEHDiCk,6708
 mltable/tests/test_partition_api.py,sha256=re7_p8O2Uhb3O52E9UGHmxx5VU_Ajtj6fr9iFH00Rko,1477
 mltable/tests/test_schema.py,sha256=dSqvIBDMl1_lJAIcUt1AD6i2UHOIW1OTterEdJgzguI,4438
-mltable/tests/test_validation_and_error_handler.py,sha256=WlgQ7IEJRMqFZJFy38D_GbR6diJG1-o55kpvP_oWvd4,5349
-mltable-1.2.0.dist-info/LICENSE.txt,sha256=FOfkEEz4uS7g278F9Rq12rqKF3lLyBUZhVpLetuZrTg,1021
-mltable-1.2.0.dist-info/METADATA,sha256=zT3S_WZyLoDywUqZl_kYRYrnxb4wHn_S93-U8QAJb34,3782
-mltable-1.2.0.dist-info/WHEEL,sha256=YUYzQ6UQdoqxXjimOitTqynltBCkwY6qlTfTh2IzqQU,97
-mltable-1.2.0.dist-info/top_level.txt,sha256=I64OiB-4blTtBhX1oQN-PS7OthFSwr7mUOLruISDi4c,8
-mltable-1.2.0.dist-info/RECORD,,
+mltable/tests/test_validation_and_error_handler.py,sha256=pkCsByeBM56pXY70X6x4X-cL6GEpn48OimdNMO1P0Eg,5294
+mltable-1.3.0.dist-info/LICENSE.txt,sha256=FOfkEEz4uS7g278F9Rq12rqKF3lLyBUZhVpLetuZrTg,1021
+mltable-1.3.0.dist-info/METADATA,sha256=5ecreF_8eJ2L6QLaYaCum89D4VgnYq_iV_BBz9E0WHY,3886
+mltable-1.3.0.dist-info/WHEEL,sha256=YUYzQ6UQdoqxXjimOitTqynltBCkwY6qlTfTh2IzqQU,97
+mltable-1.3.0.dist-info/top_level.txt,sha256=I64OiB-4blTtBhX1oQN-PS7OthFSwr7mUOLruISDi4c,8
+mltable-1.3.0.dist-info/RECORD,,
```

